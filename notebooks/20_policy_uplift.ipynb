{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Learning and Uplift Evaluation\n",
    "\n",
    "This notebook:\n",
    "1. Evaluates targeting policy performance (Qini, AUUC)\n",
    "2. Compares learned policy vs random baseline\n",
    "3. Analyzes uplift by customer segments\n",
    "4. Generates targeting recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from coupon_causal import data, features, cate, policy, viz, utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and CATE Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from previous notebook\n",
    "try:\n",
    "    results = utils.load_artifact('../models/estimation_results.joblib')\n",
    "    df = pd.read_parquet('../data/processed/coupon_data.parquet')\n",
    "    \n",
    "    cate_scores = results['cate_scores']\n",
    "    T = df['treatment'].values\n",
    "    Y = df['outcome'].values\n",
    "    \n",
    "    print(f\"Loaded {len(df):,} records\")\n",
    "    print(f\"Mean CATE: ${cate_scores.mean():.2f}\")\n",
    "except:\n",
    "    print(\"Results not found. Please run the pipeline first or execute previous notebooks.\")\n",
    "    # Fallback: generate fresh data\n",
    "    config = utils.load_config('../config/default.yaml')\n",
    "    df, _ = data.generate_synthetic_coupon_data(random_state=42)\n",
    "    \n",
    "    # Quick CATE estimation\n",
    "    from coupon_causal import propensity\n",
    "    X, T, Y, fe = features.prepare_features(df, config['features'], fit=True)\n",
    "    _, _, ensemble_prop = propensity.fit_propensity_models(X, T, config)\n",
    "    cate_scores, _ = cate.fit_x_learner(X, Y, T, ensemble_prop, config)\n",
    "    print(\"Generated fresh data and CATE estimates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qini Curve and AUUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Qini curve\n",
    "fractions, qini_values, random_baseline = policy.compute_qini_curve(\n",
    "    cate_scores, T, Y, n_bins=20\n",
    ")\n",
    "\n",
    "# Compute AUUC\n",
    "auuc = policy.compute_auuc(cate_scores, T, Y, normalize=True)\n",
    "print(f\"Area Under Uplift Curve (AUUC): {auuc:.3f}\")\n",
    "print(f\"(Positive AUUC indicates learned policy beats random targeting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Qini curve\n",
    "viz.plot_qini_curve(fractions, qini_values, random_baseline)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Policy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare policies\n",
    "policy_comparison = policy.compare_policies(cate_scores, T, Y)\n",
    "\n",
    "print(\"\\nPolicy Comparison (AUUC):\")\n",
    "for policy_name, auuc_value in policy_comparison.items():\n",
    "    print(f\"  {policy_name}: {auuc_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Budget-Constrained Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate policy under different budgets\n",
    "policy_results = policy.evaluate_policy_uplift(\n",
    "    cate_scores, T, Y, \n",
    "    budget_fractions=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    cost_per_treatment=1.0\n",
    ")\n",
    "\n",
    "print(\"\\nPolicy Performance by Budget:\")\n",
    "print(policy_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize net benefit by budget\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(policy_results['budget_fraction'] * 100, \n",
    "         policy_results['net_benefit'], \n",
    "         marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Budget (% of customers targeted)', fontsize=12)\n",
    "plt.ylabel('Net Benefit ($)', fontsize=12)\n",
    "plt.title('Net Benefit by Targeting Budget', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI by budget\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(policy_results['budget_fraction'] * 100, \n",
    "         policy_results['roi'], \n",
    "         marker='s', linewidth=2, markersize=8, color='coral')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Budget (% of customers targeted)', fontsize=12)\n",
    "plt.ylabel('Return on Investment (ROI)', fontsize=12)\n",
    "plt.title('ROI by Targeting Budget', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Segment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze uplift by segment\n",
    "if 'customer_segment' in df.columns:\n",
    "    segment_stats = policy.segment_uplift_analysis(\n",
    "        cate_scores, df, 'customer_segment', top_k=10\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    viz.plot_segment_uplift(segment_stats)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No segment column available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimal Policy and Targeting Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal threshold for a given budget\n",
    "TARGET_BUDGET = 0.2  # Target 20% of customers\n",
    "\n",
    "threshold, treatment_indicator = policy.optimal_policy_threshold(\n",
    "    cate_scores,\n",
    "    cost_per_treatment=1.0,\n",
    "    treatment_capacity=int(TARGET_BUDGET * len(df))\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal Policy (Budget={TARGET_BUDGET:.0%}):\")\n",
    "print(f\"  Threshold: ${threshold:.2f}\")\n",
    "print(f\"  Customers to target: {treatment_indicator.sum():,}\")\n",
    "print(f\"  Avg predicted uplift (targeted): ${cate_scores[treatment_indicator == 1].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create targeting recommendations\n",
    "recommendations = policy.create_targeting_recommendations(\n",
    "    cate_scores,\n",
    "    df,\n",
    "    threshold,\n",
    "    output_path='../reports/tables/targeting_recommendations.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 customers to target:\")\n",
    "print(recommendations.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Uplift Distribution by Targeting Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CATE distribution for targeted vs not targeted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cate_scores[treatment_indicator == 0], bins=30, alpha=0.6, \n",
    "         label='Not Targeted', color='gray')\n",
    "plt.hist(cate_scores[treatment_indicator == 1], bins=30, alpha=0.6, \n",
    "         label='Targeted', color='steelblue')\n",
    "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Threshold: ${threshold:.2f}')\n",
    "plt.xlabel('Predicted Treatment Effect ($)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('CATE Distribution: Targeted vs Not Targeted', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "1. **Uplift Model Performance**: AUUC shows the learned policy significantly outperforms random targeting\n",
    "2. **Optimal Budget**: ROI analysis suggests optimal budget around [X]%\n",
    "3. **High-Value Segments**: [Segment names] show highest predicted uplift\n",
    "\n",
    "### Deployment Recommendations:\n",
    "1. Target customers with predicted CATE > threshold\n",
    "2. Prioritize high-uplift segments\n",
    "3. Monitor actual uplift and recalibrate models periodically\n",
    "4. Consider A/B testing the learned policy vs. current policy\n",
    "\n",
    "### Next Steps:\n",
    "- Export targeting list to CRM/marketing platform\n",
    "- Set up monitoring dashboard\n",
    "- Plan follow-up measurement study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
